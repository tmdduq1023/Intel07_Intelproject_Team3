'''
python3 evaluate_skin_roi.py    --weights ./runs/skin_roi/best.pth   --roi-label-space ./runs/skin_roi/roi_label_space.json   --img-size 384 --batch-size 64 --workers 12   --out-json ./runs/skin_roi/test_report.json   --out-csv  ./runs/skin_roi/test_compare.csv   --max-rows 0
'''


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
테스트셋 비교 평가 스크립트
- 각 샘플(이미지-ROI-지표) 단위로 '추론값 vs 정답'을 CSV로 저장
- JSON에는 전체/ROI별/키별 집계 지표 포함

필요:
  - best.pth
  - roi_label_space.json
  - merged_test.json + 이미지 루트
"""

import os, json, argparse
from pathlib import Path
from collections import defaultdict

import numpy as np
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

import timm
import torchvision
from torchvision import transforms
from tqdm import tqdm


# ---------- 공통 유틸 ----------
def load_json(p):
    return json.loads(Path(p).read_text(encoding="utf-8"))

def clamp_bbox(x, y, w, h, W, H):
    x = max(0, min(int(x), W-1)); y = max(0, min(int(y), H-1))
    w = max(1, min(int(w), W - x)); h = max(1, min(int(h), H - y))
    return x, y, w, h


# ---------- 데이터셋 ----------
class RoiDataset(Dataset):
    def __init__(self, json_path, data_root, roi_label_space, img_size=384, pad_ratio=0.1):
        super().__init__()
        self.coco = load_json(json_path)
        self.data_root = Path(data_root)
        self.id2img = {im["id"]: im for im in self.coco["images"]}
        self.id2name = {c["id"]: c["name"] for c in self.coco["categories"]}
        self.anns_by_img = defaultdict(list)
        for a in self.coco["annotations"]:
            self.anns_by_img[a["image_id"]].append(a)

        self.roi_reg_keys = roi_label_space["regression_keys"]
        self.roi_cls_keys = roi_label_space["class_keys"]
        self.roi_cls_maps = roi_label_space["class_key_to_index"]
        self.pad_ratio = pad_ratio

        self.samples = []  # (img_id, roi_name, [x,y,w,h])
        for img_id, im in self.id2img.items():
            W, H = im.get("width"), im.get("height")
            if W is None or H is None: 
                continue
            for a in self.anns_by_img.get(img_id, []):
                if "value" in a: 
                    continue
                cname = self.id2name[a["category_id"]]
                if not cname.startswith("facepart::"):
                    continue
                roi = cname.split("facepart::",1)[1]
                bbox = a.get("bbox", [])
                if not bbox or len(bbox)!=4:
                    continue
                
                x,y,w,h = bbox
                px, py = int(w*self.pad_ratio), int(h*self.pad_ratio)
                x,y,w,h = clamp_bbox(x-px, y-py, w+2*px, h+2*py, W, H)

                if len(self.roi_reg_keys.get(roi, []))==0 and len(self.roi_cls_keys.get(roi, []))==0:
                    continue
                self.samples.append((img_id, roi, [x,y,w,h]))

        self.tf = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
        ])

    def __len__(self): return len(self.samples)

    def __getitem__(self, idx):
        img_id, roi, bbox = self.samples[idx]
        im = self.id2img[img_id]
        file_name = im["file_name"]
        img_path = self.data_root / file_name
        with Image.open(img_path).convert("RGB") as pil:
            x0,y0,w,h = bbox
            crop = pil.crop((x0, y0, x0+w, y0+h))
            x = self.tf(crop)

        R_keys = self.roi_reg_keys.get(roi, [])
        C_keys = self.roi_cls_keys.get(roi, [])
        reg_t = torch.full((len(R_keys),), float('nan'), dtype=torch.float32)
        cls_t = torch.full((len(C_keys),), -1, dtype=torch.long)

        for a in self.anns_by_img.get(img_id, []):
            if "value" not in a:
                continue
            name = self.id2name[a["category_id"]]
            v = a["value"]
            if name in R_keys:
                j = R_keys.index(name)
                try: reg_t[j] = float(v)
                except: pass
            if name in C_keys:
                try:
                    iv = int(round(float(v)))
                    maps = self.roi_cls_maps.get(roi, {}).get(name, None)
                    if maps and iv in maps["val_to_idx"]:
                        cls_t[C_keys.index(name)] = maps["val_to_idx"][iv]
                except:
                    pass

        meta = {"img_id": img_id, "roi": roi, "file_name": file_name, "bbox": [x0,y0,w,h]}
        return x, reg_t, cls_t, meta


def roi_collate(batch):
    xs, regs, clss, metas = zip(*batch)
    xs = torch.stack(xs, dim=0)

    reg_lens = [r.numel() for r in regs]
    cls_lens = [c.numel() for c in clss]
    max_R = max(reg_lens) if reg_lens else 0
    max_C = max(cls_lens) if cls_lens else 0

    if max_R > 0:
        reg_pad = torch.full((len(regs), max_R), float('nan'), dtype=torch.float32)
        for i, r in enumerate(regs):
            if r.numel() > 0:
                reg_pad[i, :r.numel()] = r
    else:
        reg_pad = torch.empty((len(regs), 0), dtype=torch.float32)

    if max_C > 0:
        cls_pad = torch.full((len(clss), max_C), -1, dtype=torch.long)
        for i, c in enumerate(clss):
            if c.numel() > 0:
                cls_pad[i, :c.numel()] = c
    else:
        cls_pad = torch.empty((len(clss), 0), dtype=torch.long)

    return xs, reg_pad, cls_pad, metas


# ---------- 모델 ----------
class RoiMultiHead(nn.Module):
    def __init__(self, backbone, roi_label_space, pretrained=False):
        super().__init__()
        assert roi_label_space is not None
        self.roi_reg_keys = roi_label_space["regression_keys"]
        self.roi_cls_keys = roi_label_space["class_keys"]
        self.roi_cls_maps = roi_label_space["class_key_to_index"]

        if backbone == "resnet50":
            m = torchvision.models.resnet50(
                weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None
            )
            in_dim = m.fc.in_features
            m.fc = nn.Identity()
            self.backbone = m
        else:
            self.backbone = timm.create_model(backbone, pretrained=pretrained, num_classes=0)
            in_dim = self.backbone.num_features

        self.reg_heads = nn.ModuleDict()
        self.cls_heads = nn.ModuleDict()

        for roi, R_keys in self.roi_reg_keys.items():
            if len(R_keys) > 0:
                self.reg_heads[roi] = nn.Linear(in_dim, len(R_keys))
        for roi, C_keys in self.roi_cls_keys.items():
            if len(C_keys) > 0:
                heads = nn.ModuleList()
                for ck in C_keys:
                    nclass = len(self.roi_cls_maps.get(roi, {}).get(ck, {}).get("values", []))
                    heads.append(nn.Linear(in_dim, nclass))
                self.cls_heads[roi] = heads

    def forward(self, x, roi_names):
        feats = self.backbone(x)
        B = feats.size(0)
        out_reg, out_cls = [None]*B, [None]*B

        for i in range(B):
            roi = roi_names[i]
            f = feats[i:i+1]
            reg_pred = None
            if roi in self.reg_heads:
                reg_pred = self.reg_heads[roi](f)
            cls_preds = None
            if roi in self.cls_heads:
                cls_preds = [head(f) for head in self.cls_heads[roi]]
            out_reg[i], out_cls[i] = reg_pred, cls_preds

        return out_reg, out_cls


# ---------- 평가(비교 저장) ----------
@torch.no_grad()
def evaluate_and_compare(model, loader, device, roi_label_space, reg_std=None, csv_path=None, max_rows=None):
    """
    - csv_path 지정 시 CSV로 저장
    - max_rows: 저장할 비교 행 수 제한(None이면 전부)
    - reg_std: Z-score 역변환용 통계
    반환: 요약 JSON(dict)
    """
    import csv
    model.eval()
    pbar = tqdm(loader, desc="test-compare", dynamic_ncols=True, leave=False)
    reg_std = reg_std or {}

    # 집계 컨테이너
    reg_sums, reg_cnts = defaultdict(float), defaultdict(int)
    cls_correct, cls_total = defaultdict(int), defaultdict(int)
    reg_roi_sums = defaultdict(lambda: defaultdict(float))
    reg_roi_cnts = defaultdict(lambda: defaultdict(int))
    cls_roi_corr = defaultdict(lambda: defaultdict(int))
    cls_roi_tot  = defaultdict(lambda: defaultdict(int))

    # CSV 준비
    writer = None
    fcsv = None
    rows_written = 0
    if csv_path:
        Path(csv_path).parent.mkdir(parents=True, exist_ok=True)
        fcsv = open(csv_path, "w", newline="", encoding="utf-8")
        writer = csv.writer(fcsv)
        writer.writerow([
            "file_name","img_id","roi","type","key",
            "target_value","pred_value","abs_err_or_correct",
            "bbox_x","bbox_y","bbox_w","bbox_h"
        ])

    for x, reg_t, cls_t, metas in pbar:
        x = x.to(device, non_blocking=True)
        reg_t = reg_t.to(device)
        cls_t = cls_t.to(device)
        roi_names = [m["roi"] for m in metas]

        out_reg, out_cls = model(x, roi_names)

        B = x.size(0)
        for i in range(B):
            meta = metas[i]
            roi = roi_names[i]
            file_name = meta["file_name"]; img_id = meta["img_id"]; bx,by,bw,bh = meta["bbox"]

            # 회귀 비교
            reg_pred_z = out_reg[i]
            R_keys = roi_label_space["regression_keys"].get(roi, [])
            if reg_pred_z is not None and len(R_keys)>0:
                Rlen = reg_pred_z.size(1)
                target_vals = reg_t[i, :Rlen]
                pred_z_vals = reg_pred_z.squeeze(0)
                mask = ~torch.isnan(target_vals)
                if mask.any():
                    p_z = pred_z_vals[mask]; t_orig = target_vals[mask]
                    idxs = mask.nonzero(as_tuple=False).squeeze(1).tolist()
                    
                    for k_idx, j in enumerate(idxs):
                        key = R_keys[j]
                        true_val = float(t_orig[k_idx].item())

                        # Z-score 예측값을 원래 스케일로 복원
                        stats = reg_std.get(key)
                        if stats:
                            pred_val = float(p_z[k_idx].item()) * stats["std"] + stats["mean"]
                        else: # 통계 없으면 Z-score가 예측값으로 간주
                            pred_val = float(p_z[k_idx].item())

                        mae = abs(pred_val - true_val)
                        reg_sums[key] += mae; reg_cnts[key] += 1
                        reg_roi_sums[roi][key] += mae; reg_roi_cnts[roi][key] += 1
                        if writer and (max_rows is None or rows_written < max_rows):
                            writer.writerow([file_name, img_id, roi, "reg", key,
                                             true_val, pred_val, mae,
                                             bx,by,bw,bh])
                            rows_written += 1

            # 분류 비교
            cls_preds = out_cls[i]
            C_keys = roi_label_space["class_keys"].get(roi, [])
            cls_maps = roi_label_space["class_key_to_index"].get(roi, {})
            if cls_preds is not None and len(C_keys)>0:
                Clen = len(cls_preds)
                t = cls_t[i, :Clen]
                for j in range(Clen):
                    key = C_keys[j]
                    if int(t[j].item()) < 0:   # 정답 없음
                        continue
                    lg = cls_preds[j]
                    pred_idx = int(lg.squeeze(0).argmax().item())
                    true_idx = int(t[j].item())
                    # 집계
                    cls_total[key] += 1; cls_roi_tot[roi][key] += 1
                    correct = int(pred_idx == true_idx)
                    cls_correct[key] += correct; cls_roi_corr[roi][key] += correct

                    if writer and (max_rows is None or rows_written < max_rows):
                        # 등급 값으로 복원(사람이 보기 좋게)
                        idx_to_val = cls_maps.get(key, {}).get("idx_to_val", {})
                        pred_val = int(idx_to_val.get(str(pred_idx), idx_to_val.get(pred_idx, pred_idx)))
                        true_val = int(idx_to_val.get(str(true_idx), idx_to_val.get(true_idx, true_idx)))
                        writer.writerow([file_name, img_id, roi, "cls", key,
                                         true_val, pred_val, correct,
                                         bx,by,bw,bh])
                        rows_written += 1

    if fcsv: fcsv.close()

    # JSON 요약
    out = {"overall": {}, "per_roi": {}, "per_key": {"regression": {}, "classification": {}}}

    # 회귀 per-key
    reg_mae_all = []
    for key, s in reg_sums.items():
        n = reg_cnts[key]
        if n > 0:
            mae = s / n
            out["per_key"]["regression"][key] = {"MAE": mae, "N": n}
            reg_mae_all.append(mae)
    out["overall"]["regression_MAE_mean_over_keys"] = float(np.mean(reg_mae_all)) if reg_mae_all else None

    # 분류 per-key
    cls_acc_all = []
    for key, corr in cls_correct.items():
        tot = cls_total[key]
        if tot > 0:
            acc = corr / tot
            out["per_key"]["classification"][key] = {"Acc": acc, "N": tot}
            cls_acc_all.append(acc)
    out["overall"]["classification_Acc_mean_over_keys"] = float(np.mean(cls_acc_all)) if cls_acc_all else None

    # ROI별 평균
    rois = set(list(reg_roi_sums.keys()) + list(cls_roi_tot.keys()))
    for roi in rois:
        entry = {}
        rvals = []
        for key, s in reg_roi_sums[roi].items():
            n = reg_roi_cnts[roi][key]
            if n>0: rvals.append(s/n)
        entry["regression_MAE_mean_over_keys"] = float(np.mean(rvals)) if rvals else None

        cvals = []
        for key, corr in cls_roi_corr[roi].items():
            tot = cls_roi_tot[roi][key]
            if tot>0: cvals.append(corr/tot)
        entry["classification_Acc_mean_over_keys"] = float(np.mean(cvals)) if cvals else None

        out["per_roi"][roi] = entry

    return out


# ---------- 메인 ----------
def main():
    ap = argparse.ArgumentParser(description="Evaluate & Compare (prediction vs ground truth)")
    ap.add_argument("--data-root", default="/home/bbang/Workspace/Intel07_Intelproject_Team3/dataset")
    ap.add_argument("--test-json", default="/home/bbang/Workspace/Intel07_Intelproject_Team3/dataset/merged_test.json")
    ap.add_argument("--weights", required=True)
    ap.add_argument("--roi-label-space", required=True)
    ap.add_argument("--backbone", type=str, default="efficientnetv2_rw_m", help="timm 라이브러리 모델 이름")
    ap.add_argument("--img-size", type=int, default=384)
    ap.add_argument("--batch-size", type=int, default=64)
    ap.add_argument("--workers", type=int, default=8)
    ap.add_argument("--device", default="", help="'cuda' 또는 'cpu'")
    ap.add_argument("--out-json", required=True, help="요약 리포트(JSON)")
    ap.add_argument("--out-csv", required=True, help="비교 테이블(CSV)")
    ap.add_argument("--max-rows", type=int, default=0, help="CSV 저장 최대 행 수(0=모두)")
    args = ap.parse_args()

    device = torch.device(args.device if args.device else ("cuda" if torch.cuda.is_available() else "cpu"))

    roi_label_space = load_json(args.roi_label_space)
    test_set = RoiDataset(args.test_json, args.data_root, roi_label_space, img_size=args.img_size)
    test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False,
                             num_workers=args.workers, pin_memory=True,
                             collate_fn=roi_collate)

    model = RoiMultiHead(backbone=args.backbone, roi_label_space=roi_label_space).to(device)
    ckpt = torch.load(args.weights, map_location="cpu")
    model.load_state_dict(ckpt["model"])
    
    reg_std = ckpt.get("reg_std") # Z-score 통계 로드
    if reg_std:
        print("[info] Loaded regression stats (reg_std) from checkpoint for Z-score denormalization.")

    max_rows = None if args.max_rows==0 else args.max_rows
    report = evaluate_and_compare(model, test_loader, device, roi_label_space,
                                  reg_std=reg_std, # 통계 전달
                                  csv_path=args.out_csv, max_rows=max_rows)

    Path(args.out_json).parent.mkdir(parents=True, exist_ok=True)
    Path(args.out_json).write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"[ok] saved JSON: {args.out_json}")
    print(f"[ok] saved CSV : {args.out_csv}")


if __name__ == "__main__":
    main()
